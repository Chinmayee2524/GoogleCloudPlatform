{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monitor wildlife health via image classification",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jKlS16hikL4S"
      },
      "source": [
        "#@title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LUt29D0MSeu"
      },
      "source": [
        "# Monitor wildlife health via image classification\n",
        "\n",
        "- **Time estimate**: 2 hours\n",
        "- **Cost estimate**: less than $30.00\n",
        "\n",
        "This _interactive notebook_ shows you how to train an image classification model to recognize animal species from [camera trap](https://en.wikipedia.org/wiki/Camera_trap) pictures.\n",
        "\n",
        "We are using the\n",
        "[WCS Camera Traps dataset](http://lila.science/datasets/wcscameratraps)\n",
        "from LILA BC _(Labeled Information Library of Alexandria: Biology and Conservation)_.\n",
        "\n",
        "Here's a quick summary of what we'll go through:\n",
        "\n",
        "1. **Create an _images database_** _(~5 minutes, costs a few cents)_: A [BigQuery](https://cloud.google.com/bigquery) table with all the image file names along with their respective category.\n",
        "1. **Train the image classifier** _(~2 hours, costs ~\\$25.00)_: A [Dataflow](https://cloud.google.com/dataflow) pipeline that creates a balanced dataset from the images database, downloads the necessary images from LILA into [Cloud Storage](https://cloud.google.com/storage), imports the data into [AI Platform](https://cloud.google.com/ai-platform) and triggers the model training.\n",
        "1. **Deploy the model** _(costs $1.25 for every hour the model is deployed)_: After the model finishes training, we look at the results and deploy it into a Cloud endpoint in AI Platform.\n",
        "1. **Classify images**: We send some images into the model and get back the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb9doxCpUcpF"
      },
      "source": [
        "# Before you begin\n",
        "\n",
        "Hi, this is an interactive notebook where we run an existing code sample, there's no need to write any code.\n",
        "\n",
        "You can run a _code cell_ by clicking the _\"Run cell\"_ button at the top left corner of each code cell. When you run a code cell, the code runs in the notebook's runtime, so you're not making any changes to your personal computer.\n",
        "\n",
        "To avoid getting errors, make sure to run _all_ the code cells _in order_.\n",
        "\n",
        "Before you begin, you need to:\n",
        "\n",
        "1. Enable the _Dataflow_ and _Cloud AutoML APIs_ in your Google Cloud project.\n",
        "\n",
        "  > ℹ️ If you don't plan to keep the resources that you create in this sample, we recommend creating a new project instead of selecting an existing project.\n",
        "  > After you finish these steps, you can delete the project, removing all resources associated with the project.\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [_Click here_ to enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=dataflow,automl.googleapis.com)\n",
        "\n",
        "  </button>\n",
        "\n",
        "1. Make sure that billing is enabled for your Cloud project.\n",
        "  [Learn how to confirm that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. Create a Cloud Storage bucket if you don't have one already.\n",
        "\n",
        "  > ℹ️ Make sure it's a _regional_ bucket in a location where\n",
        "  [AutoML is available](https://cloud.google.com/ai-platform-unified/docs/general/locations#available_regions).\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [_Click here_ to create a bucket](https://console.cloud.google.com/storage/create-bucket)\n",
        "\n",
        "  </button>\n",
        "\n",
        "1. [Create a BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets#create-dataset) if you don't have one already.\n",
        "\n",
        "  > ℹ️ The BigQuery table is created automatically if it doesn't exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWfoIueZMO9P",
        "cellView": "form"
      },
      "source": [
        "#@title My Google Cloud resources\n",
        "\n",
        "google_cloud_project = \"\" #@param {type:\"string\"}\n",
        "cloud_storage_bucket = \"\" #@param {type:\"string\"}\n",
        "cloud_storage_directory = \"samples/wildlife-insights\" #@param {type:\"string\"}\n",
        "bigquery_dataset = \"samples\" #@param {type:\"string\"}\n",
        "bigquery_table = \"wildlife_images_metadata\" #@param {type:\"string\"}\n",
        "automl_name_prefix = \"wildlife_classifier\" #@param {type:\"string\"}\n",
        "region = \"us-central1\" #@param {type:\"string\"}\n",
        "\n",
        "# Validate inputs.\n",
        "if not google_cloud_project:\n",
        "  raise ValueError('Please provide your google_cloud_project')\n",
        "if not cloud_storage_bucket:\n",
        "  raise ValueError('Please provide your cloud_storage_bucket')\n",
        "\n",
        "# Authenticate to use the Google Cloud resources.\n",
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('Authenticated')\n",
        "except ModuleNotFoundError:\n",
        "  import os\n",
        "  if os.environ.get('GOOGLE_APPLICATION_CREDENTIALS') is None:\n",
        "    raise ValueError('Please set your GOOGLE_APPLICATION_CREDENTIALS environment variable to your service account JSON file path.')\n",
        "  print(f\"GOOGLE_APPLICATION_CREDENTIALS: {service_account_file}\")\n",
        "\n",
        "%env GOOGLE_CLOUD_PROJECT={google_cloud_project}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE_APPLICATION_CREDENTIALS: /Users/dcavazos/creds/python-docs-samples-tests.json\n"
          ]
        }
      ]
    },
    {
      "source": [
        "> ℹ️ Run the cell above, and after pasting the _\"verification code\"_, press _[ENTER]_ to authenticate."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Preparing your working environment\n",
        "\n",
        "Run the following cells to download and install everything needed for the sample.\n",
        "\n",
        "<button>\n",
        "\n",
        "![View in GitHub](https://www.tensorflow.org/images/GitHub-Mark-32px.png)\n",
        "[View sample in GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/people-and-planet-ai/automl-image-classification)\n",
        "\n",
        "</button>"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "epvOb4DWY90x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZS9L7enZL1Q"
      },
      "source": [
        "# Clone the python-docs-samples respository.\n",
        "!git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git\n",
        "\n",
        "# Navigate to the sample code directory.\n",
        "%cd python-docs-samples/people-and-planet-ai/wildlife-health-via-image-classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1NlqG5KZ8vd"
      },
      "source": [
        "Now lets install the sample requirements.\n",
        "\n",
        "> When we `pip install` the requirements, there might be some warnings about conflicting dependency versions with the pre-installed libraries in Colab. For this sample, they are safe to ignore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yfhO-_DNcGU"
      },
      "source": [
        "# We need libffi-dev to launch the Dataflow pipeline.\n",
        "!apt-get -qq install libffi-dev\n",
        "\n",
        "# ℹ️ Colab already has Pillow pre-installed.\n",
        "# We remove it from the requirements.txt to avoid having a conflicting version.\n",
        "# This is not necessary in a clean virtual environment.\n",
        "!sed -i \"s/^Pillow==.*//g\" requirements.txt\n",
        "\n",
        "# Install the sample requirements.\n",
        "!pip install --quiet -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHs2UDDnT1YG"
      },
      "source": [
        "# Creating the images database\n",
        "\n",
        "First, we need to create the _images database_. This is a **one-time only** process.\n",
        "\n",
        "We run a Dataflow pipeline that creates the images database in BigQuery, it contains the following:\n",
        "\n",
        "- `category`: The species we want to predict, this is our _label_.\n",
        "- `file_name`: The path where the image file is located.\n",
        "\n",
        "AutoML expects the actual image files to live in Cloud Storage. During the first training job the images are downloaded from the LILA database and saved into Cloud Storage.\n",
        "\n",
        "The idea is that as we capture new images in the field, we save the image JPEG files directly in Cloud Storage, and its category and file name in the BigQuery images database.\n",
        "\n",
        "The initial data comes from the metadata JSON file in [WCS Camera Traps database](http://lila.science/datasets/wcscameratraps).\n",
        "We do some very basic data cleaning like discarding rows with invalid categories like `#ref!`, `empty`, `unidentifiable`, `unidentified`, `unknown` and some other categories that don't give us any useful information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivq94L2UT6FJ"
      },
      "source": [
        "# [One time only] Create the images database.\n",
        "!python create_images_metadata_table.py \\\n",
        "  --bigquery-dataset \"{bigquery_dataset}\" \\\n",
        "  --bigquery-table \"{bigquery_table}\" \\\n",
        "  --runner \"DataflowRunner\" \\\n",
        "  --job_name \"wildlife-images-metadata-`date +%Y%m%d-%H%M%S`\" \\\n",
        "  --project \"{google_cloud_project}\" \\\n",
        "  --temp_location \"gs://{cloud_storage_bucket}/{cloud_storage_directory}/temp\" \\\n",
        "  --region \"{region}\" \\\n",
        "  --worker_machine_type \"n1-standard-2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8rDiRzZcWvK"
      },
      "source": [
        "<button>\n",
        "\n",
        "![View in GitHub](https://www.tensorflow.org/images/GitHub-Mark-32px.png)\n",
        "[View `create_images_metadata_table.py`](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/dataflow-automl-vision/people-and-planet-ai/automl-image-classification/create_images_metadata_table.py)\n",
        "\n",
        "</button>\n",
        "\n",
        "> ℹ️ We need at least `n1-standard-2` [worker machines](https://cloud.google.com/compute/docs/machine-types#n1_machine_types) due to large RAM usage when parsing the metadata JSON file.\n",
        "\n",
        "You can look up the job details in the Dataflow jobs page:\n",
        "\n",
        "- [console.cloud.google.com/dataflow/jobs](https://console.cloud.google.com/dataflow/jobs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9sD-nSOmbK6"
      },
      "source": [
        "# Training the image classifier\n",
        "\n",
        "One of the challenges of this dataset is that it's very _unbalanced_.\n",
        "Meaning that there are tens of thousands of pictures of some species like\n",
        "[`tayassu pecari`](https://www.google.com/search?q=tayassu+pecari&tbm=isch),\n",
        "while only a handful of pictures of other species like\n",
        "[`tolypeutes matacus`](https://www.google.com/search?q=tolypeutes+matacus&tbm=isch).\n",
        "This could introduce a\n",
        "[_bias_](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias)\n",
        "into our model; it could predict a species just because it's more common rather than actually identifying its features.\n",
        "\n",
        "So instead of using the entire database of images, we use Dataflow to create a _balanced_ dataset.\n",
        "We specify the _minimum_ and _maximum_ number of images we want for every category.\n",
        "For categories with too many images, it will have at most `max_images_per_class` randomly selected images.\n",
        "And categories with less than `min_images_per_class` are discarded as _\"too little information to teach our model to classify this species\"_.\n",
        "\n",
        "> ℹ️ For this sample, we decided to default to using between `50` and `100` images per class to keep the training dataset small.\n",
        "> This reduces the training time at the _potential_ cost of prediction accuracy.\n",
        "> Feel free to play around with other numbers.\n",
        "\n",
        "Once Dataflow selects the images for the dataset, it\n",
        "[lazily](https://en.wikipedia.org/wiki/Lazy_evaluation)\n",
        "downloads them into Cloud Storage from the Lila Science database.\n",
        "This means we are only _preprocessing_ the images we are actually using for training instead of the entire database.\n",
        "At the same time, if an image already exists in Cloud Storage, there's nothing else to do for that image, so it also serves as a _cache_ for images that have already been preprocessed in previous runs.\n",
        "\n",
        "After all the images are stored in Cloud Storage, Dataflow creates a\n",
        "[CSV file for the AutoML dataset](https://cloud.google.com/ai-platform-unified/docs/datasets/prepare-image#csv).\n",
        "Each row includes the Cloud Storage path of an image, alongside with the category _(label)_.\n",
        "\n",
        "Then it tells AutoML to create a dataset and import the files from the CSV file.\n",
        "It waits until the dataset is ready, and finally it tells AutoML to train the model.\n",
        "This is where the Dataflow job stops.\n",
        "\n",
        "> ℹ️ We let AutoML do the _data splitting_ automatically for us.\n",
        "> By default, it uses 80% of the data for training, 10% for validation, and 10% for testing.\n",
        ">\n",
        "> See [About data splits for AutoML models](https://cloud.google.com/ai-platform-unified/docs/general/ml-use) for more information.\n",
        "\n",
        "> ℹ️ For simplicity, in this sample we are training a `CLOUD` model.\n",
        "> This allows us to deploy it to an HTTP endpoint and get predictions online.\n",
        ">\n",
        "> See [Train an AutoML Edge model](https://cloud.google.com/ai-platform-unified/docs/training/automl-edge-console)\n",
        "> for information on how to train a model for a microcontroller."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Y4byrzxVMC",
        "cellView": "form"
      },
      "source": [
        "min_images_per_class = 50 #@param {type:\"integer\"}\n",
        "max_images_per_class = 100 #@param {type:\"integer\"}\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgBiq2CzQ9Cp"
      },
      "source": [
        "# Create a balanced dataset and signal AutoML to train a model.\n",
        "!python train_model.py \\\n",
        "  --cloud-storage-path \"gs://{cloud_storage_bucket}/{cloud_storage_directory}\" \\\n",
        "  --bigquery-dataset \"{bigquery_dataset}\" \\\n",
        "  --bigquery-table \"{bigquery_table}\" \\\n",
        "  --automl-name-prefix \"{automl_name_prefix}\" \\\n",
        "  --min-images-per-class \"{min_images_per_class}\" \\\n",
        "  --max-images-per-class \"{max_images_per_class}\" \\\n",
        "  --runner \"DataflowRunner\" \\\n",
        "  --job_name \"wildlife-train-model-`date +%Y%m%d-%H%M%S`\" \\\n",
        "  --project \"{google_cloud_project}\" \\\n",
        "  --temp_location \"gs://{cloud_storage_bucket}/{cloud_storage_directory}/temp\" \\\n",
        "  --requirements_file \"requirements.txt\" \\\n",
        "  --region \"{region}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_xtp4SrwLZN"
      },
      "source": [
        "<button>\n",
        "\n",
        "![View in GitHub](https://www.tensorflow.org/images/GitHub-Mark-32px.png)\n",
        "[View `train_model.py`](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/dataflow-automl-vision/people-and-planet-ai/automl-image-classification/train_model.py)\n",
        "\n",
        "</button>\n",
        "\n",
        "> ℹ️ It can take several minutes for the job to show up in the Dataflow jobs page. See [[ARROW-8983]](https://issues.apache.org/jira/browse/ARROW-8983) for more information.\n",
        "\n",
        "You can look up the job details in the Dataflow jobs page:\n",
        "\n",
        "- [console.cloud.google.com/dataflow/jobs](https://console.cloud.google.com/dataflow/jobs)\n",
        "\n",
        "You can look up the status of your AutoML resources as well:\n",
        "\n",
        "- Datasets: [console.cloud.google.com/ai/platform/datasets](https://console.cloud.google.com/ai/platform/datasets)\n",
        "- Training: [console.cloud.google.com/ai/platform/training/training-pipelines](https://console.cloud.google.com/ai/platform/training/training-pipelines)\n",
        "- Models: [console.cloud.google.com/ai/platform/models](https://console.cloud.google.com/ai/platform/models)\n",
        "\n",
        "Training the AutoML model can take a while, depending on the dataset size and the training budget you allow.\n",
        "\n",
        "> ℹ️ You can adjust the training budget using the `--automl-budget-milli-node-hours` flag. We default to `8000` which is the minimum.\n",
        ">\n",
        "> See [AutoML pricing](https://cloud.google.com/vision/automl/pricing) and [`train_budget_milli_node_hours`](https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#imageclassificationmodelmetadata) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHVM2Nwxw9r"
      },
      "source": [
        "# Deploying the model\n",
        "\n",
        "> ℹ️ If you were disconnected from the session due to inactivity, please make sure to re-run the _\"My Google Cloud resources\"_ cell at the beginning of the notebook.\n",
        "\n",
        "After the model training has finished, we need to deploy it into an endpoint to get predictions from it.\n",
        "\n",
        "You can deploy it through the Cloud Console: [console.cloud.google.com/ai/platform/models](https://console.cloud.google.com/ai/platform/models)\n",
        "\n",
        "Alternatively, you can deploy it through the API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-YgS_IPbNfp"
      },
      "source": [
        "# First we need the model path, we can get it with gcloud.\n",
        "cmd_output = !gcloud beta ai models list \\\n",
        "  --project {google_cloud_project} \\\n",
        "  --region {region} \\\n",
        "  --filter \"display_name:{automl_name_prefix}*\" \\\n",
        "  --format \"table[no-heading](display_name,name)\" 2>/dev/null\n",
        "models = sorted([line.split() for line in cmd_output])\n",
        "model_path = models[0][1]\n",
        "\n",
        "print(f\"model_path: {model_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRRg39FcYILC"
      },
      "source": [
        "# Create an endpoint and deploy the model to it.\n",
        "!python deploy_model.py \\\n",
        "  --project {google_cloud_project} \\\n",
        "  --region {region} \\\n",
        "  --model-path {model_path} \\\n",
        "  --model-endpoint-name {automl_name_prefix}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "<button>\n",
        "\n",
        "![View in GitHub](https://www.tensorflow.org/images/GitHub-Mark-32px.png)\n",
        "[View `deploy_model.py`](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/dataflow-automl-vision/people-and-planet-ai/automl-image-classification/deploy_model.py)\n",
        "\n",
        "</button>"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jDpAELnxzf7"
      },
      "source": [
        "# Classifying images\n",
        "\n",
        "Now that we have a deployed model, we can classify images using that model.\n",
        "\n",
        "Since we don't have a camera trap readily available, lets use some images from LILA to see the model in action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_WiS5hn9wTW"
      },
      "source": [
        "## Visualizing images from LILA\n",
        "\n",
        "First, lets define some functions to help us visualize and navigate the images from the LILA database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-fuHNjhHh2d"
      },
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "def display_image(image_file, width=400):\n",
        "  base_url = 'https://lilablobssc.blob.core.windows.net/wcs-unzipped'\n",
        "  image_bytes = requests.get(f\"{base_url}/{image_file}\").content\n",
        "  if b'<Error>' in image_bytes:\n",
        "    raise ValueError(f\"Error requesting image: {base_url}/{image_file}\\n{image_bytes.decode('utf-8')}\")\n",
        "  image = Image.open(io.BytesIO(image_bytes))\n",
        "  display(image.resize((int(width), int(width / image.size[0] * image.size[1]))))\n",
        "\n",
        "\n",
        "def display_samples_for_category(category, num_samples=3, width=400):\n",
        "  client = bigquery.Client()\n",
        "  query_job = client.query(f\"\"\"\n",
        "      SELECT file_name\n",
        "      FROM `{google_cloud_project}.{bigquery_dataset}.{bigquery_table}`\n",
        "      WHERE category = '{category}'\n",
        "      LIMIT {num_samples}\n",
        "  \"\"\")\n",
        "\n",
        "  for row in query_job:\n",
        "    image_file = row['file_name']\n",
        "    print(f\"{category}: {image_file}\")\n",
        "    display_image(image_file, width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVkkjy1kHE8L"
      },
      "source": [
        "# We can explore images for a specific category like this.\n",
        "display_samples_for_category('tapirus indicus', 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFCtx6I195DA"
      },
      "source": [
        "## Online predictions\n",
        "\n",
        "Now lets see what our model thinks about some images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9jn39iv6EDu"
      },
      "source": [
        "# First we need the endpoint ID, we can get it with gcloud.\n",
        "stdout = !gcloud beta ai endpoints list \\\n",
        "  --project {google_cloud_project} \\\n",
        "  --region {region} \\\n",
        "  --filter \"display_name={automl_name_prefix}\" \\\n",
        "  --format \"table[no-heading](ENDPOINT_ID)\" 2>/dev/null\n",
        "model_endpoint_id = stdout[0]\n",
        "\n",
        "print(f\"model_endpoint_id: {model_endpoint_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDogzaQ_FgNw"
      },
      "source": [
        "def predict(image_file):\n",
        "  display_image(image_file)\n",
        "  !python predict.py \\\n",
        "    --project \"{google_cloud_project}\" \\\n",
        "    --region \"{region}\" \\\n",
        "    --model-endpoint-id \"{model_endpoint_id}\" \\\n",
        "    --image-file \"{image_file}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "<button>\n",
        "\n",
        "![View in GitHub](https://www.tensorflow.org/images/GitHub-Mark-32px.png)\n",
        "[View `predict.py`](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/dataflow-automl-vision/people-and-planet-ai/automl-image-classification/predict.py)\n",
        "\n",
        "</button>\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxy3sMAFFcAP"
      },
      "source": [
        "# Species: dicerorhinus sumatrensis\n",
        "predict('animals/0325/1529.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF-S9qpnEqjD"
      },
      "source": [
        "# Species: didelphis imperfecta\n",
        "predict('animals/0667/1214.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LneZo04sF_Bm"
      },
      "source": [
        "# Species: tapirus indicus\n",
        "predict('animals/0036/0072.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJp96gNqHUwn"
      },
      "source": [
        "# Species: leopardus wiedii\n",
        "predict('animals/0000/1705.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl523QeUGXmR"
      },
      "source": [
        "# Species: hemigalus derbyanus\n",
        "predict('animals/0036/0566.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlgjmCEQRUsS"
      },
      "source": [
        "# Species: dasypus novemcinctus\n",
        "predict('animals/0000/0425.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7INPuD2I2vV"
      },
      "source": [
        "While analyzing the model evaluation in AutoML, and some of our experiments. It might be worth trying to classify the image to a family instead of a specific species. Many species of the same family are very similar and it may be confusing the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGl_1UyiGVl6"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "To avoid incurring charges to your Google Cloud account for the resources used in this tutorial, either delete the project that contains the resources, or keep the project and delete the individual resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv7phC7WGZuT"
      },
      "source": [
        "## Deleting the project\n",
        "\n",
        "The easiest way to eliminate billing is to delete the project that you created for the tutorial.\n",
        "\n",
        "To delete the project:\n",
        "\n",
        "> ⚠️ **Caution**: Deleting a project has the following effects:\n",
        ">\n",
        "> - **Everything in the project is deleted.** If you used an existing project for this tutorial, when you delete it, you also delete any other work you've done in the project.\n",
        "> - **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in the future. To preserve the URLs that use the project ID, such as an `appspot.com` URL, delete selected resources inside the project instead of deleting the whole project.\n",
        ">\n",
        "> If you plan to explore multiple tutorials and quickstarts, reusing projects can help you avoid exceeding project quota limits.\n",
        "\n",
        "1. In the Cloud Console, go to the **Manage resources** page.\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects)\n",
        "\n",
        "  </button>\n",
        "\n",
        "1. In the project list, select the project that you want to delete, and then click **Delete**.\n",
        "\n",
        "1. In the dialog, type the project ID, and then click **Shut down** to delete the project.\n"
      ]
    }
  ]
}