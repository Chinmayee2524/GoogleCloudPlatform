{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Basics\n",
    "\n",
    "[BigQuery](https://cloud.google.com/bigquery/docs/) is a petabyte-scale analytics data warehouse that you can use to run SQL queries over vast amounts of data in near realtime. This page shows you how to get started with the Google BigQuery API using the Python client library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries used in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a client\n",
    "\n",
    "To use the BigQuery Python client library, start by initializing a client. The BigQuery client is used to send and receive messages from the BigQuery API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a query on a public dataset\n",
    "\n",
    "The following example runs a query on the BigQuery `usa_names` public dataset, which is a Social Security Administration dataset that contains all names from Social Security card applications for births that occurred in the United States after 1879.\n",
    "\n",
    "Use the [Client.query()](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.client.Client.html#google.cloud.bigquery.client.Client.query) method to run the query, and the [QueryJob.to_dataframe()](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJob.html#google.cloud.bigquery.job.QueryJob.to_dataframe) method to return the results as a [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Willie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ruth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gladys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Frances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Margaret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Helen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name\n",
       "0      Mary\n",
       "1      Ruby\n",
       "2     Annie\n",
       "3    Willie\n",
       "4      Ruth\n",
       "5    Gladys\n",
       "6     Maria\n",
       "7   Frances\n",
       "8  Margaret\n",
       "9     Helen"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT name FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    WHERE state = \"TX\"\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "query_job = client.query(\n",
    "    query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    ")  # API request - starts the query\n",
    "\n",
    "df = query_job.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new dataset\n",
    "\n",
    "A dataset is contained within a specific [project](https://cloud.google.com/bigquery/docs/projects). Datasets are top-level containers that are used to organize and control access to your [tables](https://cloud.google.com/bigquery/docs/tables) and [views](https://cloud.google.com/bigquery/docs/views). A table or view must belong to a dataset, so you need to create at least one dataset before [loading data into BigQuery](https://cloud.google.com/bigquery/loading-data-into-bigquery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define a name for the new dataset.\n",
    "dataset_id = 'test_dataset_1548268897503'\n",
    "\n",
    "# Create a DatasetReference using a chosen dataset ID.\n",
    "# The project defaults to the Client's project if not specified.\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "# Specify the geographic location where the dataset should reside.\n",
    "dataset.location = 'US'\n",
    "\n",
    "# Send the dataset to the API for creation.\n",
    "dataset = client.create_dataset(dataset)  # API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a Pandas DataFrame to a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe to /projects/ajhamilton-scratch/datasets/test_dataset_1548268897503/tables/monty_python\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    {\"title\": \"The Meaning of Life\", \"release_year\": 1983},\n",
    "    {\"title\": \"Monty Python and the Holy Grail\", \"release_year\": 1975},\n",
    "    {\"title\": \"Life of Brian\", \"release_year\": 1979},\n",
    "    {\"title\": \"And Now for Something Completely Different\", \"release_year\": 1971},\n",
    "]\n",
    "\n",
    "# Optionally set explicit indices.\n",
    "# If indices are not specified, a column will be created for the default\n",
    "# indices created by pandas.\n",
    "index = [\"Q24980\", \"Q25043\", \"Q24953\", \"Q16403\"]\n",
    "df = pandas.DataFrame(records, index=pandas.Index(index, name=\"wikidata_id\"))\n",
    "\n",
    "table_ref = dataset_ref.table(\"monty_python\")\n",
    "job = client.load_table_from_dataframe(df, table_ref, location=\"US\")\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load query results to a table\n",
    "\n",
    "For more information, see [Writing Query Results](https://cloud.google.com/bigquery/docs/writing-results) in the BigQuery documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results loaded to table /projects/ajhamilton-scratch/datasets/test_dataset_1548268897503/tables/your_new_table_id\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT corpus\n",
    "    FROM `bigquery-public-data.samples.shakespeare`\n",
    "    GROUP BY corpus;\n",
    "\"\"\"\n",
    "table_ref = dataset.table(\"your_new_table_id\")\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    destination=table_ref\n",
    ")\n",
    "\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_job = client.query(sql, location=\"US\", job_config=job_config)\n",
    "\n",
    "query_job.result()  # Waits for the query to finish\n",
    "print(\"Query results loaded to table {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a local file to a table\n",
    "\n",
    "The example below demonstrates how to load a local CSV file into a new or existing table. See [SourceFormat](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.SourceFormat.html#google.cloud.bigquery.job.SourceFormat) in the Python client library documentation for a list of available source formats. For more information, see [Loading Data into BigQuery from a Local Data Source](https://cloud.google.com/bigquery/docs/loading-data-local) in the BigQuery documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 rows into test_dataset_1548268897503:/projects/ajhamilton-scratch/datasets/test_dataset_1548268897503/tables/us_states_from_local_file.\n"
     ]
    }
   ],
   "source": [
    "source_filename = 'resources/us-states.csv'\n",
    "\n",
    "table_ref = dataset_ref.table('us_states_from_local_file')\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    autodetect=True\n",
    ")\n",
    "\n",
    "with open(source_filename, 'rb') as source_file:\n",
    "    job = client.load_table_from_file(\n",
    "        source_file,\n",
    "        table_ref,\n",
    "        location='US',  # Must match the destination dataset location.\n",
    "        job_config=job_config)  # API request\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('Loaded {} rows into {}:{}.'.format(\n",
    "    job.output_rows, dataset_id, table_ref.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Google Cloud Storage to a table\n",
    "\n",
    "The example below demonstrates how to load a local CSV file into a new or existing table. See [SourceFormat](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.SourceFormat.html#google.cloud.bigquery.job.SourceFormat) in the Python client library documentation for a list of available source formats. For more information, see [Introduction to Loading Data from Cloud Storage](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage) in the BigQuery documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job f65c1470-3e8b-4b0f-8a44-ff6a3f5cbaf0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 rows.\n"
     ]
    }
   ],
   "source": [
    "# Configure the load job\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField('name', 'STRING'),\n",
    "        bigquery.SchemaField('post_abbr', 'STRING')\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "uri = 'gs://cloud-samples-data/bigquery/us-states/us-states.csv'\n",
    "destination_table_ref = dataset.table('us_states_from_gcs')\n",
    "\n",
    "# Start the load job\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, destination_table_ref, job_config=job_config)\n",
    "print('Starting job {}'.format(load_job.job_id))\n",
    "\n",
    "load_job.result()  # Waits for table load to complete.\n",
    "print('Job finished.')\n",
    "\n",
    "# Retreive the destination table\n",
    "destination_table = client.get_table(table_ref)\n",
    "print('Loaded {} rows.'.format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a parameterized query\n",
    "\n",
    "BigQuery supports query parameters to help prevent [SQL injection](https://en.wikipedia.org/wiki/SQL_injection) when queries are constructed using user input. This feature is only available with [standard SQL syntax](https://cloud.google.com/bigquery/docs/reference/standard-sql/). Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\n",
    "\n",
    "To specify a named parameter, use the `@` character followed by an [identifier](https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#identifiers), such as `@param_name`. For example, this query finds all the words in a specific Shakespeare corpus with counts that are at least the specified value.\n",
    "\n",
    "For more information, see [Running Parameterized Queries](https://cloud.google.com/bigquery/docs/parameterized-queries) in the BigQuery documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>my</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>that</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>me</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  word_count\n",
       "0    the         614\n",
       "1      I         577\n",
       "2    and         490\n",
       "3     to         486\n",
       "4      a         407\n",
       "5     of         367\n",
       "6     my         314\n",
       "7     is         307\n",
       "8     in         291\n",
       "9    you         271\n",
       "10  that         270\n",
       "11    me         263"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query\n",
    "sql = \"\"\"\n",
    "    SELECT word, word_count\n",
    "    FROM `bigquery-public-data.samples.shakespeare`\n",
    "    WHERE corpus = @corpus\n",
    "    AND word_count >= @min_word_count\n",
    "    ORDER BY word_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameter values in a query job configuration\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ScalarQueryParameter(\"corpus\", \"STRING\", \"romeoandjuliet\"),\n",
    "        bigquery.ScalarQueryParameter(\"min_word_count\", \"INT64\", 250),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Start the query job\n",
    "query_job = client.query(sql, location=\"US\", job_config=job_config)\n",
    "\n",
    "# Return the results as a Pandas DataFrame\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up\n",
    "\n",
    "The following code deletes the dataset created for this tutorial, including all tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dataset: /projects/ajhamilton-scratch/datasets/test_dataset_1548268897503\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the dataset from the API\n",
    "dataset = client.get_dataset(client.dataset(dataset_id))\n",
    "\n",
    "# Delete the dataset and its contents\n",
    "client.delete_dataset(dataset, delete_contents=True)\n",
    "\n",
    "print('Deleted dataset: {}'.format(dataset.path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local google-cloud-bigquery development",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
